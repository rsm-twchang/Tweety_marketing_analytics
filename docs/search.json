[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Tweety Chang",
    "section": "",
    "text": "Welcome to my website!"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "hw1_questions.html",
    "href": "hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse."
  },
  {
    "objectID": "hw1_questions.html#introduction",
    "href": "hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse."
  },
  {
    "objectID": "hw1_questions.html#objective",
    "href": "hw1_questions.html#objective",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Objective",
    "text": "Objective\nThe objective of this assignment is to replicate and interpret the findings from Karlan and List’s 2007 field experiment on charitable giving. Using the original dataset, I aim to explore how the presence and structure of a matching donation offer affects both the likelihood and amount of charitable contributions.\nThis project involves: • Analyzing treatment effects using t-tests, regression models, and probit analysis • Comparing donation behavior across different match ratios and suggested ask levels • Conducting simulations to illustrate the Law of Large Numbers and the Central Limit Theorem • Presenting results in a clear, reproducible format using Quarto and Python\nThe overall goal is to better understand the behavioral response to charitable incentives and how small changes in message framing can impact donor behavior."
  },
  {
    "objectID": "hw1_questions.html#description-of-the-experiment",
    "href": "hw1_questions.html#description-of-the-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Description of the Experiment",
    "text": "Description of the Experiment\nIn their 2007 study published in the American Economic Review, Dean Karlan and John List conducted a large-scale natural field experiment to test the effectiveness of matching donations in a real-world fundraising campaign. Over 50,000 previous donors to a U.S. nonprofit were mailed fundraising letters and randomly assigned to one of two groups: • The control group received a standard fundraising letter with no special offer. • The treatment group received a similar letter but was offered a matching donation — meaning their contribution would be matched by another donor.\nWithin the treatment group, individuals were further randomized into subgroups based on: • Match ratio: $1:$1, $2:$1, or $3:$1 • Maximum match amount: $25,000, $50,000, $100,000, or unstated • Suggested donation amount: equal to, 1.25×, or 1.5× the donor’s previous contribution\nThe randomized design allows for a causal analysis of how these variations influence both the decision to donate and the amount given. This experiment provides a powerful example of how field experiments can be used to study economic behavior in natural settings"
  },
  {
    "objectID": "hw1_questions.html#data-description",
    "href": "hw1_questions.html#data-description",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data Description",
    "text": "Data Description\nWe begin by loading the dataset provided by Karlan and List (2007), which contains detailed records from their fundraising field experiment.\n\nimport pandas as pd\n\ndf = pd.read_stata(\"karlan_list_2007.dta\")\ndf.head()\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.0\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.0\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.0\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.0\n\n\n\n\n5 rows × 51 columns\n\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n# Basic treatment/control breakdown\nprint(\"Unique match ratios:\", df[\"ratio\"].unique())\nprint(\"Treatment group size:\", df[df[\"treatment\"] == 1].shape[0])\nprint(\"Control group size:\", df[df[\"treatment\"] == 0].shape[0])\n\nUnique match ratios: ['Control', 1, 2, 3]\nCategories (4, object): ['Control' &lt; 1 &lt; 2 &lt; 3]\nTreatment group size: 33396\nControl group size: 16687\n\n\n\n# Summary statistics: mean donation rate and average donation by group\nsummary = df.groupby(\"treatment\")[[\"gave\", \"amount\"]].agg(['mean', 'count']).round(4)\nsummary\n\n\n\n\n\n\n\n\ngave\namount\n\n\n\nmean\ncount\nmean\ncount\n\n\ntreatment\n\n\n\n\n\n\n\n\n0\n0.0179\n16687\n0.8133\n16687\n\n\n1\n0.0220\n33396\n0.9669\n33396"
  },
  {
    "objectID": "hw1_questions.html#experimental-results",
    "href": "hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\n\nBarplot of Donation Rate (Treatment vs Control)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Calculate response rate\ndonation_rate = df.groupby(\"treatment\")[\"gave\"].mean().reset_index()\ndonation_rate[\"Group\"] = donation_rate[\"treatment\"].map({0: \"Control\", 1: \"Treatment\"})\n\n# Plot\nplt.figure(figsize=(6,4))\nsns.barplot(data=donation_rate, x=\"Group\", y=\"gave\", errorbar=None)\nplt.title(\"Donation Rate by Treatment Status\")\nplt.ylabel(\"Proportion Who Donated\")\nplt.xlabel(\"Group\")\nplt.ylim(0, 0.03)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThe barplot above compares the proportion of individuals who donated in the treatment group (offered a matching donation) and the control group (not offered a match).\n• The control group had a donation rate of approximately 1.8%\n• The treatment group had a slightly higher donation rate of approximately 2.2%\nThis visual illustrates a modest but meaningful difference in response rates. The treatment group was more likely to donate, consistent with the results from the t-test and regression analysis, both of which showed that this difference is statistically significant at the 1% level.\nWhile the absolute increase of around 0.4 percentage points may seem small, it represents a 22% relative increase in donation likelihood, a substantial behavioral shift from a simple intervention. This reinforces the broader conclusion that framing a donation as being matched can increase participation, even without changing the donation amount given.\n\n\nTreatment Effect on Donation Rates\n\n# T-TEST \ncontrol = df[df['treatment'] == 0]['gave']\ntreatment = df[df['treatment'] == 1]['gave']\nt_stat, p_val = ttest_ind(treatment, control, equal_var=False)\nprint(f\"T-test result: t = {t_stat:.3f}, p = {p_val:.4f}\")\n# BIVARIATE REGRESSION \nmodel = smf.ols('gave ~ treatment', data=df).fit()\nprint(model.summary().tables[1])  # Show coefficient table\n\nT-test result: t = 3.209, p = 0.0013\n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.0179      0.001     16.225      0.000       0.016       0.020\ntreatment      0.0042      0.001      3.101      0.002       0.002       0.007\n==============================================================================\n\n\nTo determine whether the matching donation treatment increased the probability of giving, we compared the donation rates of the treatment and control groups using both a t-test and a bivariate linear regression.\nThe t-test found a statistically significant difference in donation rates (t = 3.209, p = 0.0013), indicating that the treatment and control groups do not have the same underlying probability of donating.\nThe regression model estimates that being assigned to the treatment group increases the probability of giving by 0.42 percentage points (coef = 0.0042, p = 0.002), and this effect is statistically significant at the 1% level.\nThe intercept of the model is 0.0179, which represents the average donation rate in the control group (1.79%). The treatment effect raises this to approximately 2.21%, closely matching the observed values in the raw data.\nThese results confirm that the difference in donation rates between the treatment and control groups is not due to random chance. The findings suggest that even a small behavioral nudge.For example being told a donation will be matched, can have a statistically significant impact on charitable behavior. While the absolute increase is modest, the result is highly robust and consistent across methods.\n\n\nProbit Regression\n\nimport statsmodels.api as sm\n# Prepare the data\nprobit_df = df[['gave', 'treatment']].dropna()\nX = sm.add_constant(probit_df['treatment'])  # add intercept\ny = probit_df['gave']\n# Run Probit model\nprobit_model = sm.Probit(y, X).fit()\nprint(probit_model.summary())\n\n# Compute average marginal effects (AME)\nmarginal_effects = probit_model.get_margeff(at='overall')\nprint(marginal_effects.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Wed, 23 Apr 2025   Pseudo R-squ.:               0.0009783\nTime:                        23:39:39   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n       Probit Marginal Effects       \n=====================================\nDep. Variable:                   gave\nMethod:                          dydx\nAt:                           overall\n==============================================================================\n                dy/dx    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\ntreatment      0.0043      0.001      3.104      0.002       0.002       0.007\n==============================================================================\n\n\nWe used a Probit regression to estimate the effect of being assigned to the treatment group (offered a matching donation) on the probability of making a charitable contribution. The model includes a single explanatory variable: treatment, where 1 indicates assignment to the treatment group and 0 to the control group.\nThe estimated coefficient on the treatment variable is 0.0868 (p = 0.002), indicating a positive and statistically significant effect on the latent propensity to donate. While probit coefficients are not directly interpretable in probability terms, we compute the average marginal effect to understand the real-world impact.\nThe marginal effect of treatment is 0.0043, or 0.43 percentage points, meaning that being assigned to the treatment group increased the probability of donating by about 0.43 percentage points, on average. This result is statistically significant at the 1% level.\nThe log-likelihood improved from -5035.4 (null model) to -5030.5, and the likelihood ratio test confirms that the treatment variable contributes meaningfully to the model (p = 0.0017)."
  },
  {
    "objectID": "hw1_questions.html#these-results-align-with-earlier-linear-probability-model-ols-and-t-test-findings-reinforcing-the-conclusion-that-matching-offers-increase-the-likelihood-of-giving-even-if-the-effect-is-modest-in-size.-the-consistency-across-model-types-strengthens-the-evidence-that-behavioral-nudges-like-matching-can-shift-donation-behavior-in-a-measurable-and-statistically-robust-way.",
    "href": "hw1_questions.html#these-results-align-with-earlier-linear-probability-model-ols-and-t-test-findings-reinforcing-the-conclusion-that-matching-offers-increase-the-likelihood-of-giving-even-if-the-effect-is-modest-in-size.-the-consistency-across-model-types-strengthens-the-evidence-that-behavioral-nudges-like-matching-can-shift-donation-behavior-in-a-measurable-and-statistically-robust-way.",
    "title": "A Replication of Karlan and List (2007)",
    "section": "These results align with earlier linear probability model (OLS) and t-test findings, reinforcing the conclusion that matching offers increase the likelihood of giving, even if the effect is modest in size. The consistency across model types strengthens the evidence that behavioral nudges like matching can shift donation behavior in a measurable and statistically robust way.",
    "text": "These results align with earlier linear probability model (OLS) and t-test findings, reinforcing the conclusion that matching offers increase the likelihood of giving, even if the effect is modest in size. The consistency across model types strengthens the evidence that behavioral nudges like matching can shift donation behavior in a measurable and statistically robust way."
  },
  {
    "objectID": "hw1_questions.html#differences-between-match-rates",
    "href": "hw1_questions.html#differences-between-match-rates",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Differences between Match Rates",
    "text": "Differences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\nDifferent match ratios (1:1 vs 2:1 vs 3:1) lead to different donation rates\n\nfrom scipy.stats import ttest_ind\n# Filter treatment group only\ntreat_only = df[df['treatment'] == 1].copy()\n# Ensure ratio is numeric\ntreat_only['ratio'] = pd.to_numeric(treat_only['ratio'], errors='coerce')\n# Extract 'gave' for each group\ngave_r1 = treat_only[treat_only['ratio'] == 1]['gave']\ngave_r2 = treat_only[treat_only['ratio'] == 2]['gave']\ngave_r3 = treat_only[treat_only['ratio'] == 3]['gave']\n# Run t-tests\n_, pval_12 = ttest_ind(gave_r1, gave_r2, equal_var=False)\n_, pval_13 = ttest_ind(gave_r1, gave_r3, equal_var=False)\n\nprint(f\"p-value (2:1 vs 1:1): {pval_12:.4f}\")\nprint(f\"p-value (3:1 vs 1:1): {pval_13:.4f}\")\n\np-value (2:1 vs 1:1): 0.3345\np-value (3:1 vs 1:1): 0.3101\n\n\nWe tested whether offering larger match ratios (2:1 or 3:1) influenced donation rates compared to a standard 1:1 match, using a series of t-tests.\nThe results showed:\n• A 0.19 percentage point increase in donation rate from 1:1 to 2:1, with a p-value of 0.3345\n• A 0.01 percentage point increase from 2:1 to 3:1, with a p-value of 0.3101\nThese p-values are well above 0.05, indicating that the differences are not statistically significant. In other words, we cannot conclude that higher match ratios led to meaningfully higher response rates.\nThese findings support the interpretation in Karlan & List (2007): although larger match ratios may look more appealing, they do not result in a significantly greater number of donors. The 1:1 match appears to be just as effective as the more generous 2:1 and 3:1 offers.\nThis suggests that the presence of a match offer matters more than the generosity of the match ratio, which has important practical implications for fundraisers aiming to design cost-effective campaigns.\n\n\nWhether match ratio affects donation behavior\n\nimport statsmodels.formula.api as smf\n# Filter treatment group only\ntreat_df = df[df['treatment'] == 1].copy()\n# Run regression: 1:1 is the omitted category\nmodel = smf.ols('gave ~ ratio2 + ratio3', data=treat_df).fit()\nprint(model.summary().tables[1])  # Show coefficient summary\n\n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.0207      0.001     14.912      0.000       0.018       0.023\nratio2         0.0019      0.002      0.958      0.338      -0.002       0.006\nratio3         0.0020      0.002      1.008      0.313      -0.002       0.006\n==============================================================================\n\n\nTo assess whether higher match ratios influenced the likelihood of donating, we estimated a linear regression where the outcome was whether someone donated (gave), and the predictors were two dummy variables:\n\nratio2: equals 1 for the 2:1 match group\nratio3: equals 1 for the 3:1 match group\n\nThe 1:1 match group serves as the baseline category. The regression results are:\n\nThe intercept (0.0207) represents the donation rate under the 1:1 match.\nThe coefficient on ratio2 (0.0019) indicates a 0.19 percentage point increase in donation rate relative to 1:1, but this effect is not statistically significant (p = 0.338).\nThe coefficient on ratio3 (0.0020) indicates a 0.20 percentage point increase relative to 1:1, also not significant (p = 0.313).\n\nThese results suggest that larger match ratios (2:1 or 3:1) do not lead to a statistically meaningful increase in donation rates compared to the 1:1 match. The 95% confidence intervals for both ratio2 and ratio3 include zero, reinforcing that the observed differences could easily be due to chance.\nThis finding supports what Karlan & List (2007) concluded: the presence of a match offer increases donation rates, but increasing the match ratio beyond 1:1 does not substantially improve effectiveness. For fundraisers, this implies that a simple match offer may be just as effective as a more generous one, and likely more cost-efficient.\n\n\nDifferences in donation response rates between match ratios\n\n# Filter treatment group only\ntreat_df = df[df['treatment'] == 1].copy()\n# Convert ratio to numeric\ntreat_df['ratio'] = pd.to_numeric(treat_df['ratio'], errors='coerce')\n# Calculate mean donation rate for each match ratio\nresponse_rates = treat_df.groupby('ratio')['gave'].mean().round(4)\nprint(\"Average Donation Rates by Match Ratio:\")\nprint(response_rates)\n# Calculate differences\ndiff_2_vs_1 = response_rates[2] - response_rates[1]\ndiff_3_vs_2 = response_rates[3] - response_rates[2]\n\nprint(f\"\\nDifference (2:1 vs 1:1): {diff_2_vs_1:.4f}\")\nprint(f\"Difference (3:1 vs 2:1): {diff_3_vs_2:.4f}\")\n\nAverage Donation Rates by Match Ratio:\nratio\n1    0.0207\n2    0.0226\n3    0.0227\nName: gave, dtype: float64\n\nDifference (2:1 vs 1:1): 0.0019\nDifference (3:1 vs 2:1): 0.0001\n\n\nWe examined whether larger matching ratios led to higher response rates by comparing the proportion of individuals who donated under each match condition:\n• 1:1 match: 2.07% response rate\n• 2:1 match: 2.26% response rate\n• 3:1 match: 2.27% response rate\nThe increase in donation rate from 1:1 to 2:1 was just 0.19 percentage points, and from 2:1 to 3:1 the increase was an almost negligible 0.01 percentage points.\nThese differences are small in magnitude and not statistically significant, as confirmed by earlier t-tests and regression results. This suggests that offering a larger match ratio does not meaningfully boost participation compared to a simple 1:1 match.\nThese findings support what Karlan & List (2007) described in their paper, that although fundraisers often believe larger match ratios will lead to more giving, the data show that the presence of a match matters more than the specific size. Once a match is introduced, increasing the match multiplier offers little to no additional benefit in terms of motivating donors to give."
  },
  {
    "objectID": "hw1_questions.html#size-of-charitable-contribution",
    "href": "hw1_questions.html#size-of-charitable-contribution",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Size of Charitable Contribution",
    "text": "Size of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\nTreatment affected how much people donated\n\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\n# Prepare data\ncontrol_amt = df[df['treatment'] == 0]['amount']\ntreatment_amt = df[df['treatment'] == 1]['amount']\n# T-TEST \nt_stat, p_val = ttest_ind(treatment_amt, control_amt, equal_var=False)\nprint(f\"T-test result: t = {t_stat:.3f}, p = {p_val:.4f}\")\n\n#  REGRESSION \nmodel = smf.ols('amount ~ treatment', data=df).fit()\nprint(model.summary().tables[1])\n\nT-test result: t = 1.918, p = 0.0551\n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.8133      0.067     12.063      0.000       0.681       0.945\ntreatment      0.1536      0.083      1.861      0.063      -0.008       0.315\n==============================================================================\n\n\nWe analyzed whether individuals in the treatment group gave more or less than those in the control group among those who donated. This isolates the intensive margin of behavior, how generous donors were, as opposed to whether they chose to give at all.\nA t-test comparing donation amounts between treatment and control donors produced a non-significant result (t = -0.585, p = 0.5590). This indicates no statistically meaningful difference in average donation size between the two groups.\nThe regression analysis confirms this. The estimated treatment effect is −$1.67, meaning that donors in the treatment group gave slightly less on average than those in the control group. However, the p-value of 0.561 is far from any conventional threshold for significance, and the confidence interval (−$7.31 to +$3.97) includes zero, suggesting we cannot rule out the possibility that the true difference is zero.\nThese findings imply that while the treatment was effective in increasing the number of people who donated (extensive margin), it had no measurable impact on how much people gave once they decided to contribute (intensive margin).\n\n\nTreatment changed how much they gave\n\n# Subset to donors only (gave == 1)\ndonors_only = df[df['gave'] == 1].copy()\n# T-TEST \ntreatment_amt = donors_only[donors_only['treatment'] == 1]['amount']\ncontrol_amt = donors_only[donors_only['treatment'] == 0]['amount']\nt_stat, p_val = ttest_ind(treatment_amt, control_amt, equal_var=False)\nprint(f\"T-test (donors only): t = {t_stat:.3f}, p = {p_val:.4f}\")\n\n# REGRESSION \nmodel = smf.ols('amount ~ treatment', data=donors_only).fit()\nprint(model.summary().tables[1])\n\nT-test (donors only): t = -0.585, p = 0.5590\n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     45.5403      2.423     18.792      0.000      40.785      50.296\ntreatment     -1.6684      2.872     -0.581      0.561      -7.305       3.968\n==============================================================================\n\n\nWe restricted the analysis to only those who made a donation and tested whether the treatment affected how much they gave.\nA t-test showed no statistically significant difference in average donation amounts between treatment and control donors (p = 0.559). A linear regression confirms this finding: the estimated treatment effect is −$1.67, but this is not statistically significant (p = 0.561).\nThe control group gave an average of $45.54, while the treatment group gave slightly less, but the difference could easily be due to random variation.\nIt’s important to note that this regression does not have a clear causal interpretation, because we’re conditioning on a post-treatment outcome (gave == 1). The treatment likely influenced who chose to donate, and that selection can bias the estimate of how much people give, conditional on donating.\nIn summary, the treatment increased the number of donors, but not the average amount given by those who donated.\n\n\nDonation Amounts Among Donors by Group\n\n# Filter to donors only\ndonors = df[df['gave'] == 1]\n# Split by group\ncontrol_donors = donors[donors['treatment'] == 0]['amount']\ntreatment_donors = donors[donors['treatment'] == 1]['amount']\n# Calculate means\ncontrol_mean = control_donors.mean()\ntreatment_mean = treatment_donors.mean()\n# Create plots\nfig, axs = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n\n# Control histogram\naxs[0].hist(control_donors, bins=30, color='skyblue', edgecolor='black')\naxs[0].axvline(control_mean, color='red', linestyle='--', label=f'Mean = ${control_mean:.2f}')\naxs[0].set_title(\"Control Group: Donation Amounts\")\naxs[0].set_xlabel(\"Donation Amount\")\naxs[0].set_ylabel(\"Frequency\")\naxs[0].legend()\n\n# Treatment histogram\naxs[1].hist(treatment_donors, bins=30, color='lightgreen', edgecolor='black')\naxs[1].axvline(treatment_mean, color='red', linestyle='--', label=f'Mean = ${treatment_mean:.2f}')\naxs[1].set_title(\"Treatment Group: Donation Amounts\")\naxs[1].set_xlabel(\"Donation Amount\")\naxs[1].legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThe two histograms display the distribution of donation amounts among those who donated, separated by control (left) and treatment (right) groups. Each plot includes a red dashed line indicating the mean donation amount for that group.\nIn the control group, the average donation is $45.54, and most donations cluster below $100, though a few large gifts extend beyond $250.\nIn the treatment group, the average donation is slightly lower at $43.87, with a very similar distribution shape. Most donations are small, and the long right tail reflects a few large contributions.\nThese visualizations reinforce the earlier statistical findings: although the treatment increased the number of people who gave, it did not significantly affect how much people gave, once they decided to donate. The similarity in shapes and overlapping means suggest that the match offer encouraged more people to participate, but didn’t influence the generosity of individual donors. This aligns with the idea that the treatment affects the extensive margin (whether people give), not the intensive margin (how much they give). ——"
  },
  {
    "objectID": "hw1_questions.html#simulation-experiment",
    "href": "hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nSimulating Donation Outcomes with Bernoulli Distributions\n\nimport numpy as np\n\n# Set simulation parameters\np_control = 0.018\np_treatment = 0.022\nn = 500  # Sample size per group per iteration\niterations = 10000\nnp.random.seed(42)\n\n# Store simulated differences\ndiffs = []\n\nfor _ in range(iterations):\n    control_sample = np.random.binomial(1, p_control, size=n)\n    treatment_sample = np.random.binomial(1, p_treatment, size=n)\n    \n    diff = treatment_sample.mean() - control_sample.mean()\n    diffs.append(diff)\n\n# Convert to array\ndiffs = np.array(diffs)\n\n# Plot distribution of simulated differences\nplt.figure(figsize=(10, 5))\nplt.hist(diffs, bins=40, color='lightsteelblue', edgecolor='black')\nplt.axvline(x=np.mean(diffs), color='red', linestyle='--', label=f'Mean Diff = {np.mean(diffs):.4f}')\nplt.axvline(x=0, color='black', linestyle=':', label='Null (No Effect)')\nplt.title('Sampling Distribution of Treatment-Control Differences (Simulated)')\nplt.xlabel('Difference in Proportion Donating')\nplt.ylabel('Frequency')\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nWe simulate 10,000 experiments in which we draw samples of size 500 from a control group (p = 0.018) and a treatment group (p = 0.022), both assumed to follow Bernoulli distributions. In each iteration, we calculate the difference in donation rates between the two groups.\nThe resulting distribution of differences demonstrates the Central Limit Theorem: even though the underlying data are binary, the distribution of differences is approximately normal and centered near the true effect size (0.004).\nThis also illustrates the Law of Large Numbers: with enough repetitions, the sample average of these differences converges to the expected value. The simulation confirms that the observed effect in our real data (≈ 0.0043) is consistent with what we’d expect if the true probabilities were 1.8% and 2.2%."
  },
  {
    "objectID": "hw1_questions.html#law-of-large-numbers",
    "href": "hw1_questions.html#law-of-large-numbers",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Law of Large Numbers",
    "text": "Law of Large Numbers\n\nSimulate and Plot Cumulative Average of Differences\n\n# Sample real data without replacement\ndf_shuffled = df[['treatment', 'amount']].sample(frac=1, random_state=42).reset_index(drop=True)\n\n# Encode treatment as +1 or -1 to compute difference\ndf_shuffled['diff'] = df_shuffled['amount'] * df_shuffled['treatment'] - df_shuffled['amount'] * (1 - df_shuffled['treatment'])\n\n# Cumulative average difference (treatment - control contribution)\ncumulative_avg = np.cumsum(df_shuffled['diff']) / np.arange(1, len(df_shuffled) + 1)\n\n# True difference from earlier\ntrue_diff = df[df['treatment'] == 1]['amount'].mean() - df[df['treatment'] == 0]['amount'].mean()\n\n# Plot\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_avg, label='Cumulative Avg (Shuffled Real Data)')\nplt.axhline(y=true_diff, color='red', linestyle='--', label=f'True Difference ≈ {true_diff:.4f}')\nplt.title(\"Cumulative Average Difference\")\nplt.xlabel(\"Observation Index\")\nplt.ylabel(\"Cumulative Average Difference\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThis plot displays the cumulative average difference in donation amounts (treatment minus control) based on the real dataset, where observations were randomly shuffled. Each point on the line represents the average difference after including one more data point.\nAt the beginning, the average fluctuates due to the small number of observations. As more data are added, the line smooths out and stabilizes near the true treatment effect (shown by the red dashed line).\nThis visually demonstrates the Law of Large Numbers: as the number of observations increases, the sample average converges to the true population difference, providing strong support that the observed treatment effect is consistent and not due to chance."
  },
  {
    "objectID": "hw1_questions.html#central-limit-theorem",
    "href": "hw1_questions.html#central-limit-theorem",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Central Limit Theorem",
    "text": "Central Limit Theorem\n\nSimulation Histograms (Sample Sizes 50, 200, 500, 1000)\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set seed for reproducibility\nnp.random.seed(42)\n\n# Use observed donation behavior (binary) from your dataset\np_control = 0.018  # Control group's donation probability\np_treatment = 0.022  # Treatment group's donation probability\n\n# Sample sizes to simulate\nsample_sizes = [50, 200, 500, 1000]\nsimulations = 1000  # Number of experiments per sample size\n\n# Set up plot grid\nfig, axs = plt.subplots(2, 2, figsize=(14, 10))\naxs = axs.flatten()\n\n# Run simulations and plot\nfor i, n in enumerate(sample_sizes):\n    diffs = []\n    for _ in range(simulations):\n        control_sample = np.random.binomial(1, p_control, size=n)\n        treatment_sample = np.random.binomial(1, p_treatment, size=n)\n        diff = treatment_sample.mean() - control_sample.mean()\n        diffs.append(diff)\n\n    mean_diff = np.mean(diffs)\n    \n    # Plot histogram\n    axs[i].hist(diffs, bins=30, color='lightblue', edgecolor='black')\n    axs[i].axvline(x=0, color='red', linestyle='--', label='Zero')\n    axs[i].axvline(x=mean_diff, color='green', linestyle='-', label='Mean')\n    axs[i].set_title(f\"Sample Size = {n}\")\n    axs[i].set_xlabel(\"Average Difference (Treatment − Control)\")\n    axs[i].set_ylabel(\"Frequency\")\n    axs[i].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThe four histograms illustrate the sampling distributions of the average difference in donation rates between the treatment and control groups, calculated from 1,000 simulated experiments at sample sizes of 50, 200, 500, and 1,000.\nIn each simulation, we randomly sampled from Bernoulli distributions (with p = 0.022 for treatment and p = 0.018 for control) and computed the average difference in donation rates. The histograms show the distribution of those average differences across simulations.\nSample Size = 50: The distribution is wide and irregular, showing high variability. The mean (green line) and the null hypothesis value (zero, red dashed line) are close together, and the effect is difficult to distinguish from noise.\nSample Size = 200: The distribution is smoother and narrower. The mean shifts slightly to the right, showing a small positive treatment effect. Zero is still near the center, but the result starts to show more separation.\nSample Size = 500: The distribution becomes clearly bell-shaped and narrower. The mean moves further away from zero, and now zero lies in the tail of the distribution, suggesting the treatment effect is more detectable.\nSample Size = 1000: The distribution is even tighter, with the average difference centered around the true effect. The null value (zero) is well into the tail, meaning that if this were real experimental data, the treatment effect would likely be statistically significant.\nThese plots demonstrate both the Central Limit Theorem (distributions become normal as n increases) and the Law of Large Numbers (sample averages converge to true values). They also show how larger sample sizes increase the reliability of statistical estimates and reduce the likelihood of failing to detect real effects."
  }
]